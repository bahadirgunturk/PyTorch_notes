{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJZ0uLTSPCPX"
      },
      "source": [
        "**Convolutional Neural Networks**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iANn4858oOsP"
      },
      "source": [
        "*Build a CNN model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfshyZH1PDoe",
        "outputId": "211f8f8b-cda6-4bd0-a38d-99d3bb306aae"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# transformations to be applied during dataloading\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "\n",
        "# Download dataset\n",
        "#https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./cifar10_data/',\n",
        "    train=True,\n",
        "    transform=train_transform,\n",
        "    download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./cifar10_data/',\n",
        "    train=False,\n",
        "    transform=test_transform,\n",
        "    download=True)\n",
        "\n",
        "# Check out some attributes of the dataset\n",
        "print(train_dataset.data.shape)\n",
        "print(len(train_dataset.targets))\n",
        "print(train_dataset.classes)\n",
        "print(train_dataset.class_to_idx)\n",
        "print(train_dataset.transforms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_abljiqYqhnI",
        "outputId": "719ab6a6-5daf-4b07-a4fd-bf0e1be0b99c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# hyperparameters\n",
        "num_epochs = 100\n",
        "num_classes = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# data loader\n",
        "# __getitem__ of the dataset returns a tuple of (image,target_index)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "# Check out \n",
        "X, y = next(iter(train_loader))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iElB5NpfyFoS",
        "outputId": "ffa74665-420d-41b3-fdf9-6d0eb82e3240"
      },
      "outputs": [],
      "source": [
        "# The model\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "  def __init__(self, in_channels=3, num_classes=10):\n",
        "    super().__init__()\n",
        "\n",
        "    # Define the layers\n",
        "    self.conv2d_1 = torch.nn.Conv2d(in_channels=in_channels,\n",
        "                                    out_channels=16,\n",
        "                                    kernel_size=5,\n",
        "                                    stride=1,\n",
        "                                    padding=2)\n",
        "    \n",
        "    self.conv2d_2 = torch.nn.Conv2d(in_channels=16,\n",
        "                                    out_channels=32,\n",
        "                                    kernel_size=5,\n",
        "                                    stride=1,\n",
        "                                    padding=2)\n",
        "\n",
        "    self.batchnorm_1 = torch.nn.BatchNorm2d(16)\n",
        "    self.batchnorm_2 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "    self.maxpool = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "    # Here, the size is worked out by hand!\n",
        "    self.fc = torch.nn.Linear(8*8*32,num_classes)\n",
        "  \n",
        "  def forward(self,input):\n",
        "\n",
        "    # first convolutional layer\n",
        "    x = self.conv2d_1(input)\n",
        "    x = self.batchnorm_1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)     # the size (h,w) is reduced to 16x16\n",
        "\n",
        "    # second convolutional layer\n",
        "    x = self.conv2d_2(x)\n",
        "    x = self.batchnorm_2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)     # the size (h,w) is reduced to 8x8\n",
        "\n",
        "    # flatten\n",
        "    x = x.view(-1,8*8*32)   # we know shape, 8*8*32; the first dim is batch size\n",
        "    # OR\n",
        "    #batch_size = x.size(0)\n",
        "    #x = x.view(batch_size,-1)\n",
        "    # OR\n",
        "    # define self.flatten = nn.Flatten() in the __init__, then\n",
        "    #x = self.flatten(x)\n",
        "\n",
        "    # fully connected\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "print(model)\n",
        "# Note that this prints the layers defined in the constructor __init__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELXnZrGI9eb8"
      },
      "source": [
        "*Summarize the model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x96f1Krb9mBp",
        "outputId": "e3c6cae2-9feb-42f8-c8d2-91e8ce8a3dc2"
      },
      "outputs": [],
      "source": [
        "# This prints the forward process\n",
        "# !pip install torchinfo # if using Google Colab, else pip install torchinfo\n",
        "from torchinfo import summary\n",
        "# Include the size of the input tensor. Include what columns to be displayed\n",
        "summary(model, (1, 3, 32,32), col_names=[\"kernel_size\", \"output_size\", \"num_params\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5L1hsw_EZ1a"
      },
      "outputs": [],
      "source": [
        "# Check out the torchinfo for some large models\n",
        "#modelX = torchvision.models.resnet18()\n",
        "#summary(modelX, (1, 3, 224, 224), col_names=[\"kernel_size\", \"output_size\", \"num_params\"], depth=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z57KPp6i56zj",
        "outputId": "13bdf64e-1212-4d9a-9a55-7f1b18a433b2"
      },
      "outputs": [],
      "source": [
        "# test the model\n",
        "\n",
        "X, y = next(iter(train_loader))\n",
        "X = X.to(device)\n",
        "y_pred = model(X)\n",
        "\n",
        "print(X.shape)\n",
        "print(y_pred.shape)   # One-hot encoded logits\n",
        "print(y.shape)        # Note that it is an integer label!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niWE4Y3aP8-S"
      },
      "source": [
        "*Train and test the model; and use Tensorboard to track*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfdhmvEgODZI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter('logs')\n",
        "\n",
        "# For different runs, you can create subfolders\n",
        "# writer = SummaryWriter('logs/run1')\n",
        "\n",
        "\n",
        "# Set the loss function and the optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()     \n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "# Define a function to train the model for one epoch\n",
        "def train_model(epoch, train_loader):\n",
        "  \n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # For loss calculation\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  dataset_size = len(train_loader.dataset)\n",
        "\n",
        "  # Go over each batch\n",
        "  for X, y in train_loader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_function(y_pred,y)  \n",
        "    # In the above\n",
        "    #   input:y_pred is logits, target y is integer index.\n",
        "    #   target could also be a vector of probabilities\n",
        "    #     in that case, y.softmax(1) could be used to convert to probabilities  \n",
        "    \n",
        "    # Zero the gradients, backpropagate the gradients, update the parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate loss\n",
        "    total_loss += loss_function(y_pred, y).item()\n",
        "    total_correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "  # Add images to tensorboard\n",
        "  img_grid = torchvision.utils.make_grid(X)\n",
        "  writer.add_image('batch images', img_grid)\n",
        "\n",
        "  # Add loss and accuracy to tensorboard\n",
        "  writer.add_scalar(\"Train Loss\", total_loss/dataset_size, epoch )\n",
        "  writer.add_scalar(\"Train Accuracy\", total_correct/dataset_size, epoch )\n",
        "  print(f\"Epoch: {epoch}, \\\n",
        "          Training Loss:{total_loss/dataset_size:0.4f}, \\\n",
        "          Training Accuracy:{total_correct/dataset_size:0.4f}\")\n",
        "\n",
        "\n",
        "# Define a function to test the model\n",
        "def test_model(epoch, test_loader):\n",
        "  \n",
        "  # For loss calculation\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  dataset_size = len(test_loader.dataset)\n",
        "\n",
        "  # Put the model into evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Do not calculate gradients\n",
        "  with torch.no_grad():\n",
        "    for X,y in test_loader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Calculate loss\n",
        "      total_loss += loss_function(y_pred, y).item()\n",
        "      total_correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "\n",
        "  writer.add_graph(model,X)\n",
        "\n",
        "  writer.add_scalar(\"Test Loss\", total_loss/dataset_size, epoch )\n",
        "  writer.add_scalar(\"Test Accuracy\", total_correct/dataset_size, epoch )\n",
        "  print(f\"Test Loss: {total_loss/dataset_size:0.4f}, \\\n",
        "          Test Accuracy: {total_correct/dataset_size:0.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2GNJnyYDso-"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "  # Train loss\n",
        "  train_model(epoch,train_loader)\n",
        "\n",
        "  # Test loss\n",
        "  test_model(epoch, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyEZzCTwtLSN"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "#%reload_ext tensorboard\n",
        "%tensorboard --logdir=logs \n",
        "#when running code locally, tensorboard --logdir=logs returns localhost for web.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4TN2PZ46k6w"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=logs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Note: Fully convolutional CNN\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# global avg. pooling used in ResNet -- essentially averaging outputs if size >1\n",
        "# This makes the network fully convolutional, meaning any input size would work\n",
        "\n",
        "# Suppose the convolutional layers resulted in a shape like this\n",
        "x = torch.randn((1,512,8,8))\n",
        "\n",
        "# Then, we can do avg pooling as follows\n",
        "avgpool = nn.AvgPool2d(x.size()[2:4]) # no trainable parameters\n",
        "y = avgpool(x)\n",
        "print(y.shape)\n",
        "\n",
        "# OR\n",
        "y = F.adaptive_avg_pool2d(x,(1,1))  # no trainable parameters\n",
        "print(y.shape)\n",
        "\n",
        "# Instead of avgpooling maxpooling is also possible\n",
        "# Other implementation possibilities are available as well ...\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
