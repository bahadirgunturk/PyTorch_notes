{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJZ0uLTSPCPX"
      },
      "source": [
        "**Convolutional Neural Networks**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iANn4858oOsP"
      },
      "source": [
        "*Build a CNN model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfshyZH1PDoe",
        "outputId": "211f8f8b-cda6-4bd0-a38d-99d3bb306aae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "(50000, 32, 32, 3)\n",
            "50000\n",
            "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
            "StandardTransform\n",
            "Transform: Compose(\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# transformations to be applied during dataloading\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "\n",
        "# Download dataset\n",
        "#https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./cifar10_data/',\n",
        "    train=True,\n",
        "    transform=train_transform,\n",
        "    download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./cifar10_data/',\n",
        "    train=False,\n",
        "    transform=test_transform,\n",
        "    download=True)\n",
        "\n",
        "# Check out some attributes of the dataset\n",
        "print(train_dataset.data.shape)\n",
        "print(len(train_dataset.targets))\n",
        "print(train_dataset.classes)\n",
        "print(train_dataset.class_to_idx)\n",
        "print(train_dataset.transforms)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_abljiqYqhnI",
        "outputId": "719ab6a6-5daf-4b07-a4fd-bf0e1be0b99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 32, 32])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# hyperparameters\n",
        "num_epochs = 100\n",
        "num_classes = 10\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "\n",
        "# data loader\n",
        "# __getitem__ of the dataset returns a tuple of (image,target_index)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "# Check out \n",
        "X, y = next(iter(train_loader))\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iElB5NpfyFoS",
        "outputId": "ffa74665-420d-41b3-fdf9-6d0eb82e3240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (conv2d_1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2d_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (batchnorm_1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm_2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu): ReLU()\n",
            "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# The model\n",
        "\n",
        "class ConvNet(torch.nn.Module):\n",
        "  def __init__(self, in_channels=3, num_classes=10):\n",
        "    super().__init__()\n",
        "\n",
        "    # Define the layers\n",
        "    self.conv2d_1 = torch.nn.Conv2d(in_channels=in_channels,\n",
        "                                    out_channels=16,\n",
        "                                    kernel_size=5,\n",
        "                                    stride=1,\n",
        "                                    padding=2)\n",
        "    \n",
        "    self.conv2d_2 = torch.nn.Conv2d(in_channels=16,\n",
        "                                    out_channels=32,\n",
        "                                    kernel_size=5,\n",
        "                                    stride=1,\n",
        "                                    padding=2)\n",
        "\n",
        "    self.batchnorm_1 = torch.nn.BatchNorm2d(16)\n",
        "    self.batchnorm_2 = torch.nn.BatchNorm2d(32)\n",
        "\n",
        "    self.maxpool = torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "    # Here, the size is worked out by hand!\n",
        "    self.fc = torch.nn.Linear(8*8*32,num_classes)\n",
        "  \n",
        "  def forward(self,input):\n",
        "\n",
        "    # first convolutional layer\n",
        "    x = self.conv2d_1(input)\n",
        "    x = self.batchnorm_1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)     # the size (h,w) is reduced to 16x16\n",
        "\n",
        "    # second convolutional layer\n",
        "    x = self.conv2d_2(x)\n",
        "    x = self.batchnorm_2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.maxpool(x)     # the size (h,w) is reduced to 8x8\n",
        "\n",
        "    # flatten\n",
        "    x = x.view(-1,8*8*32)   # we know shape, 8*8*32; the first dim is batch size\n",
        "    # OR\n",
        "    #batch_size = x.size(0)\n",
        "    #x = x.view(batch_size,-1)\n",
        "    # OR\n",
        "    # define self.flatten = nn.Flatten() in the __init__, then\n",
        "    #x = self.flatten(x)\n",
        "\n",
        "    # fully connected\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "print(model)\n",
        "# Note that this prints the layers defined in the constructor __init__\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELXnZrGI9eb8"
      },
      "source": [
        "*Summarize the model*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x96f1Krb9mBp",
        "outputId": "e3c6cae2-9feb-42f8-c8d2-91e8ce8a3dc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #\n",
              "===================================================================================================================\n",
              "ConvNet                                  --                        [1, 10]                   --\n",
              "├─Conv2d: 1-1                            [5, 5]                    [1, 16, 32, 32]           1,216\n",
              "├─BatchNorm2d: 1-2                       --                        [1, 16, 32, 32]           32\n",
              "├─ReLU: 1-3                              --                        [1, 16, 32, 32]           --\n",
              "├─MaxPool2d: 1-4                         2                         [1, 16, 16, 16]           --\n",
              "├─Conv2d: 1-5                            [5, 5]                    [1, 32, 16, 16]           12,832\n",
              "├─BatchNorm2d: 1-6                       --                        [1, 32, 16, 16]           64\n",
              "├─ReLU: 1-7                              --                        [1, 32, 16, 16]           --\n",
              "├─MaxPool2d: 1-8                         2                         [1, 32, 8, 8]             --\n",
              "├─Linear: 1-9                            --                        [1, 10]                   20,490\n",
              "===================================================================================================================\n",
              "Total params: 34,634\n",
              "Trainable params: 34,634\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 4.55\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 0.39\n",
              "Params size (MB): 0.14\n",
              "Estimated Total Size (MB): 0.54\n",
              "==================================================================================================================="
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This prints the forward process\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "# Include the size of the input tensor. Include what columns to be displayed\n",
        "summary(model, (1, 3, 32,32), col_names=[\"kernel_size\", \"output_size\", \"num_params\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5L1hsw_EZ1a"
      },
      "outputs": [],
      "source": [
        "# Check out the torchinfo for some large models\n",
        "#modelX = torchvision.models.resnet18()\n",
        "#summary(modelX, (1, 3, 224, 224), col_names=[\"kernel_size\", \"output_size\", \"num_params\"], depth=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z57KPp6i56zj",
        "outputId": "13bdf64e-1212-4d9a-9a55-7f1b18a433b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 32, 32])\n",
            "torch.Size([64, 10])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# test the model\n",
        "\n",
        "X, y = next(iter(train_loader))\n",
        "X = X.to(device)\n",
        "y_pred = model(X)\n",
        "\n",
        "print(X.shape)\n",
        "print(y_pred.shape)   # One-hot encoded logits\n",
        "print(y.shape)        # Note that it is an integer label!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niWE4Y3aP8-S"
      },
      "source": [
        "*Train and test the model; and use Tensorboard to track*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfdhmvEgODZI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter('logs')\n",
        "\n",
        "# For different runs, you can create subfolders\n",
        "# writer = SummaryWriter('logs/run1')\n",
        "\n",
        "\n",
        "# Set the loss function and the optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()     \n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "# Define a function to train the model for one epoch\n",
        "def train_model(epoch, train_loader):\n",
        "  \n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # For loss calculation\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  dataset_size = len(train_loader.dataset)\n",
        "\n",
        "  # Go over each batch\n",
        "  for X, y in train_loader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = loss_function(y_pred,y)  \n",
        "    # In the above\n",
        "    #   input:y_pred is logits, target y is integer index.\n",
        "    #   target could also be a vector of probabilities\n",
        "    #     in that case, y.softmax(1) could be used to convert to probabilities  \n",
        "    \n",
        "    # Zero the gradients, backpropagate the gradients, update the parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate loss\n",
        "    total_loss += loss_function(y_pred, y).item()\n",
        "    total_correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "  # Add images to tensorboard\n",
        "  img_grid = torchvision.utils.make_grid(X)\n",
        "  writer.add_image('batch images', img_grid)\n",
        "\n",
        "  # Add loss and accuracy to tensorboard\n",
        "  writer.add_scalar(\"Train Loss\", total_loss/dataset_size, epoch )\n",
        "  writer.add_scalar(\"Train Accuracy\", total_correct/dataset_size, epoch )\n",
        "  print(f\"Epoch: {epoch}, \\\n",
        "          Training Loss:{total_loss/dataset_size:0.4f}, \\\n",
        "          Training Accuracy:{total_correct/dataset_size:0.4f}\")\n",
        "\n",
        "\n",
        "# Define a function to test the model\n",
        "def test_model(epoch, test_loader):\n",
        "  \n",
        "  # For loss calculation\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  dataset_size = len(test_loader.dataset)\n",
        "\n",
        "  # Put the model into evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # Do not calculate gradients\n",
        "  with torch.no_grad():\n",
        "    for X,y in test_loader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # Calculate loss\n",
        "      total_loss += loss_function(y_pred, y).item()\n",
        "      total_correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "\n",
        "  writer.add_graph(model,X)\n",
        "\n",
        "  writer.add_scalar(\"Test Loss\", total_loss/dataset_size, epoch )\n",
        "  writer.add_scalar(\"Test Accuracy\", total_correct/dataset_size, epoch )\n",
        "  print(f\"Test Loss: {total_loss/dataset_size:0.4f}, \\\n",
        "          Test Accuracy: {total_correct/dataset_size:0.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2GNJnyYDso-"
      },
      "outputs": [],
      "source": [
        "for epoch in range(num_epochs):\n",
        "  # Train loss\n",
        "  train_model(epoch,train_loader)\n",
        "\n",
        "  # Test loss\n",
        "  test_model(epoch, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyEZzCTwtLSN"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "#%reload_ext tensorboard\n",
        "%tensorboard --logdir=logs \n",
        "#when running code locally, tensorboard --logdir=logs returns localhost for web.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4TN2PZ46k6w"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=logs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Note: Fully convolutional CNN\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# global avg. pooling used in ResNet -- essentially averaging outputs if size >1\n",
        "# This makes the network fully convolutional, meaning any input size would work\n",
        "\n",
        "# Suppose the convolutional layers resulted in a shape like this\n",
        "x = torch.randn((1,512,8,8))\n",
        "\n",
        "# Then, we can do avg pooling as follows\n",
        "avgpool = nn.AvgPool2d(x.size()[2:4]) # no trainable parameters\n",
        "y = avgpool(x)\n",
        "print(y.shape)\n",
        "\n",
        "# OR\n",
        "y = F.adaptive_avg_pool2d(x,(1,1))  # no trainable parameters\n",
        "print(y.shape)\n",
        "\n",
        "# Instead of avgpooling maxpooling is also possible\n",
        "# Other implementation possibilities are available as well ...\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
