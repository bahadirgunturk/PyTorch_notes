{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fully Connected NN and Saving-Loading Models**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VAlcIJO7KLfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Building ANN model*"
      ],
      "metadata": {
        "id": "By49fO97n8mi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h1t5UEOMJ1A9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "# Create a transform to be applied to each sample\n",
        "#   .ToTensor() is critical; without it, dataloader will give error\n",
        "transform1 = transforms.Compose([\n",
        "    transforms.ToTensor(),  # converts PIL image or numpy array (HxWxC) into a \n",
        "                            #   torch.FloatTensor (CxHxW), scales it to [0,1] \n",
        "    transforms.Normalize(mean=[0.5],std=[0.5]) # for 1 channel\n",
        "                            #   [0.5,0.5,0.5] for 3 channels\n",
        "                            # Conversion from RGB to gray could also be useful\n",
        "                            # Transforms can also be added to the dataloader\n",
        "    ])\n",
        "\n",
        "# Download the dataset and apply the transform for each sample\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transform1\n",
        "    )\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform = transform1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Take a look at a sample\n",
        "sample_id = 0\n",
        "image = train_data.data[sample_id]        \n",
        "label = train_data.targets[sample_id]\n",
        "\n",
        "print(image.shape, image.max())  # Note: image is not yet reshaped or normalized\n",
        "\n",
        "plt.imshow(image, cmap=\"gray\") # .squeeze() if img.shape is (1,28,28)\n",
        "plt.title(train_data.classes[label.item()])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "7jpYybFOKve6",
        "outputId": "e74739d2-79a0-4ac1-94da-b977ed02123a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([28, 28]) tensor(255, dtype=torch.uint8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Ankle boot')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Define a fully connected model*"
      ],
      "metadata": {
        "id": "Rir76kIxNB3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, do it with nn.Sequential()\n",
        "import torch.nn as nn\n",
        "\n",
        "MyModel1 = nn.Sequential(\n",
        "    nn.Flatten(start_dim=1),    # To preserve batch_size, start_dim=1 (default)\n",
        "    nn.Linear(28*28, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10)\n",
        ")\n",
        "\n",
        "print(MyModel1)\n",
        "print(MyModel1[1])\n"
      ],
      "metadata": {
        "id": "4UErToeyX7YI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a81bfc-43cd-4e99-9c56-c0a8df9cd5d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Linear(in_features=784, out_features=512, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: nn.Flatten() has default start_dim 1\n",
        "# That means, it will preserve the batch size; for instance:\n",
        "input = torch.randn(32, 1, 5, 5)\n",
        "m = nn.Flatten()\n",
        "output = m(input)\n",
        "output.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wx_LMsc8bOvk",
        "outputId": "8c32a471-d810-4b67-c90e-e9a8c40cf985"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second, do it as nn.Module class\n",
        "import torch.nn as nn\n",
        "\n",
        "# A fully connected model\n",
        "class MyModel2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # When .view() is used, you should preserve the batch size:\n",
        "        # batch_size = x.size(0)\n",
        "        # x.view(batch_size,-1)\n",
        "        \n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "Z2I3PKjgNI8Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Set the device*"
      ],
      "metadata": {
        "id": "l-_jZIikSGnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = MyModel2().to(device)   # send the model to device\n",
        "\n",
        "print(model) #check out the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjpKqHRLSL5A",
        "outputId": "6ed06690-b7ed-4f77-f33b-061bb9f10501"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyModel2(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Pass a random input to check the model*"
      ],
      "metadata": {
        "id": "5cWQ_r5-SuEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# single input\n",
        "x = torch.randn((1,28,28),dtype=torch.float32)\n",
        "x = x.to(device)    # the model and input should be on the same device!\n",
        "y_pred = model(x)\n",
        "print(y_pred.shape)\n",
        "\n",
        "# batch input\n",
        "x = torch.randn((32,1,28,28),dtype=torch.float32)\n",
        "x = x.to(device)    # the model and input should be on the same device!\n",
        "y_pred = model(x)\n",
        "print(y_pred.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "tduF7EtgS136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbed3d77-2087-4b57-ec35-bcb9d48e6a59"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n",
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# repeat the above with the first model\n",
        "# batch input\n",
        "x = torch.randn((32,1,28,28),dtype=torch.float32)\n",
        "x = x.to(device)    \n",
        "# y_pred = MyModel1(x) # This will give error b/c MyModel1 is not send to device\n",
        "y_pred = MyModel1.to(device)(x)\n",
        "print(y_pred.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiI7GPPZdk6G",
        "outputId": "fb76bcee-c679-4f2a-cee9-b805a35929c9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create dataloader*"
      ],
      "metadata": {
        "id": "kHm667VbVNce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader #creates an iterable around a dataset\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_data,batch_size,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data,batch_size,shuffle=False)"
      ],
      "metadata": {
        "id": "wCiSc92ZVRXx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Set the loss function*"
      ],
      "metadata": {
        "id": "2szzp7sGTwa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "NXlq4U5_T2Te"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Set the optimizer*"
      ],
      "metadata": {
        "id": "PmYeBzaeUAJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(),lr=1e-3)"
      ],
      "metadata": {
        "id": "rIBZS9v-UCfa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Train the model*"
      ],
      "metadata": {
        "id": "fROrl6xPV1Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "# Put the model in training mode\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for X,y in train_dataloader:\n",
        "\n",
        "    # Send to device\n",
        "    X = X.to(device)  \n",
        "    y = y.to(device)\n",
        "\n",
        "    # Make a prediction\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_fn(y_pred,y)\n",
        "\n",
        "    # Zero the gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Propagate loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the parameters\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch: {epoch}/{num_epochs}, Loss: {loss.item():0.4f}\")\n"
      ],
      "metadata": {
        "id": "jOxRBELYV44a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Test the model*"
      ],
      "metadata": {
        "id": "SJRuAReKZD4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put the model in test mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize some parameters to get the loss values\n",
        "total_loss = 0\n",
        "total_correct = 0\n",
        "dataset_size = len(test_dataloader.dataset)\n",
        "\n",
        "# Gradients will not be calculated\n",
        "with torch.no_grad():\n",
        "  for X,y in test_dataloader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # Calculate loss\n",
        "    total_loss += loss_fn(y_pred, y).item()\n",
        "    total_correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "  print(f\"Accuracy: {total_correct/dataset_size:0.4f}, Avg loss: {total_loss/dataset_size:0.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq-OFqZPZGDz",
        "outputId": "35a24489-c8f2-4f90-a0be-c1a90052ef2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8213, Avg loss: 0.0078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Check out the model on a single input*"
      ],
      "metadata": {
        "id": "--oaUY9BbDe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = next(iter(test_dataloader))\n",
        "X = X.to(device)\n",
        "y = y.to(device)\n",
        "\n",
        "# Get a specific sample\n",
        "sample_id = 2\n",
        "X0 = X[sample_id]\n",
        "y0 = y[sample_id]\n",
        "\n",
        "# Make the prediction. It is of vector size 10; get the argmax\n",
        "y_pred = model(X0).argmax(1)\n",
        "\n",
        "# The shape is (1,28,28). Convert it to (28,28)\n",
        "#print(X0.shape)\n",
        "#print(X0.squeeze().shape)\n",
        "\n",
        "# After squeezing, move it to cpu, convert to numpy, and gray scale \n",
        "plt.imshow(X0.squeeze().cpu().numpy(), cmap=\"gray\")\n",
        "plt.title(train_data.classes[y_pred.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Hp_tvtIHbKS1",
        "outputId": "ddbc65b6-418c-4bc3-9415-915b35667ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Trouser')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARZElEQVR4nO3dfYxV9Z3H8fcHeRJQCqUgWlaKD1HXh9EQFi3ZuGm2sXQNGhNTNYrGLTZp4zZxY41tVrbZJmazbXWzm6bjaotuF9ekshofNlXXLBiMAQlFqm4FBQFHUB4EkSeH7/4xBzPg3N8Z7rlP8Pu8ksncOd977v3OyXzm3Ht+95yfIgIzO/4NaXcDZtYaDrtZJhx2s0w47GaZcNjNMuGwm2XCYTfLhMN+nJD0cb+vg5L29Pv5hnb3Z+0nf6jm+CNpHfDXEfH8ALWhEfFp67vqrB5y5D37cU7S5ZI2SvqBpPeBX0kaIek+Se8VX/dJGlHc/2ZJLx3xGCHpzOL2bEmvS9olaZOkv+13v7+StFLSDklLJV3Yr7au6GEVsFvS0NZsATvEYc/DKcB44HRgHvBDYCbQBVwEzAB+NMjHehC4LSJOAs4H/gdA0sXAQ8BtwBeBXwJPHvonUrgO+CbwBe/ZW89hz8NB4J6I2BcRe4AbgB9HxJaI+AD4e+DGQT7WAeA8SSdHxPaIWFEsnwf8MiJeiYjeiFgA7KPvn8oh/xwRG4oerMUc9jx8EBF7+/18KrC+38/ri2WDcQ0wG1gv6X8lXVosPx24o3gJv0PSDmDKEY+7ob72rREc9jwceRT2PfrCecifFMsAdgOjDhUknXLYA0Usi4g5wETgv4DHitIG4CcR8YV+X6MiYmGiD2shhz1PC4EfSfqSpAnA3wH/XtR+D/yppC5JI4H5h1aSNFzSDZLGRsQBYCd9bxEAHgC+I+nP1Ge0pG9KOqllv5UlOex5+gdgObAKeA1YUSwjIv4I/Bh4HngLeOmIdW8E1knaCXyHvvf/RMRy4NvAvwDbgTXAzU3+PewoeJzdLBPes5tlwmE3y4TDbpYJh90sEy39fLIkHw2sw0knpUevJk6cWLO2Z0/6w2pDh6b/BPbt25esn3DCCXXXyw4OjxgxIllfu3Ztsp6riNBAyyuFXdIVwP3ACcC/RcS9VR7veCUNuO0/U/ZHP2PGjGT99ttvr1lbuXJlct1TTjklWV+zZk2yPmbMmGR93LhxNWsHDhxIrjtt2rRk/eqrr07W7XB1v4yXdALwr8A3gPOA6ySd16jGzKyxqrxnnwGsiYi3I2I/8CgwpzFtmVmjVQn7aRx+YsPGYtlhJM2TtFzS8grPZWYVNf0AXUR0A93gA3Rm7VRlz76JvlMYD/lysczMOlCVsC8DzpL0FUnDgW8BTzamLTNrtEonwkiaDdxH39DbQxHxk5L7Z/kyfsiQ9P/UgwcPJutLlixJ1mfNmnXUPQ3Wzp07k/VRo0Yl66lx/E8++aTSY1955ZXJ+lNPPZWsH6+aMs4eEc8Az1R5DDNrDX9c1iwTDrtZJhx2s0w47GaZcNjNMuGwm2XC8221QNk4epmurq5kfdu2bTVrH374YXLdKuPkAFu3bk3WP/209ixPZaf+nnnmmcn6Oeeck6znOs5ei/fsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMeejsGlF3BNTW8dvLJJyfXLTv9tuqlpFOXgy577DJTpkwpv5N9xnt2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTHmfvAJMmTaq0fmo21LJLhZeNs5eNo6dOYYX06b1lvZVdxjo1VbV9nvfsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmPM7eAc4///xK66fG2U888cTkur29vZXqZeP0KWVj+GXnu0+YMKHu585RpbBLWgfsAnqBTyNieiOaMrPGa8Se/S8iIj0TgZm1nd+zm2WiatgD+J2kVyXNG+gOkuZJWi5pecXnMrMKqr6MnxURmyRNBJ6T9GZELO5/h4joBroBJKXPfDCzpqm0Z4+ITcX3LcAiYEYjmjKzxqs77JJGSzrp0G3g68DqRjVmZo1V5WX8JGBRMe3uUOA/IuK/G9JVZi688MJkff/+/cn63r17a9bKpmROXdcdyq87n5ouukzZlM1lve3evbvu585R3WGPiLeBixrYi5k1kYfezDLhsJtlwmE3y4TDbpYJh90sEz7FtQPMmJH+LFLqcsyQHl4ru9Tz2LFjk/UVK1Yk611dXcn69u3ba9bKTmEtGzbcsGFDsm6H857dLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEx9k7wLnnnpuspy4VDelx+DFjxiTX7enpSdZnzpyZrFeZErrsMtRDh6b/PKucXpsj79nNMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0x4nL0DlJ1TXnZOepVx9scffzxZryo1LXPZdNBlhg8fXmn93HjPbpYJh90sEw67WSYcdrNMOOxmmXDYzTLhsJtlwuPsHWDixInJ+ieffJKsl51TnrJw4cK614Xya7+PHz++Zm3r1q2VnrvsuvJ2uNI9u6SHJG2RtLrfsvGSnpP0VvF9XHPbNLOqBvMy/tfAFUcsuwt4ISLOAl4ofjazDlYa9ohYDBx5/Z85wILi9gLgqgb3ZWYNVu979kkRcejiZe8Dk2rdUdI8YF6dz2NmDVL5AF1EhKSaR4giohvoBkjdz8yaq96ht82SJgMU37c0riUza4Z6w/4kMLe4PRd4ojHtmFmzlL6Ml7QQuByYIGkjcA9wL/CYpFuB9cC1zWzyeFc2Xvzxxx8n62XXV0958cUX614X4OWXX07WL7300pq11Lnug1F1nD43pX8lEXFdjdLXGtyLmTWRPy5rlgmH3SwTDrtZJhx2s0w47GaZ8Cmux4Fhw4bVrJVdhrrsFNUy69atS9ZnzZpVsyap0nN/9NFHldbPjffsZplw2M0y4bCbZcJhN8uEw26WCYfdLBMOu1kmPM5+DCi7VHRqnH3t2rWNbucwGzduTNaHDKm9P6lyCWw7et6zm2XCYTfLhMNulgmH3SwTDrtZJhx2s0w47GaZ8Dj7MeDAgQPJ+ujRo2vWVq9eXbPWCE8//XSyfuedd9aspcbgrfG8tc0y4bCbZcJhN8uEw26WCYfdLBMOu1kmHHazTHic/RhQZWrjd955p4GdfN6qVauS9eHDh9espc7DH4zdu3dXWj83pXt2SQ9J2iJpdb9l8yVtkrSy+Jrd3DbNrKrBvIz/NXDFAMt/HhFdxdczjW3LzBqtNOwRsRjY1oJezKyJqhyg+56kVcXL/HG17iRpnqTlkpZXeC4zq6jesP8COAPoAnqAn9a6Y0R0R8T0iJhe53OZWQPUFfaI2BwRvRFxEHgAmNHYtsys0eoKu6TJ/X68GmjueZRmVlnpOLukhcDlwARJG4F7gMsldQEBrANua2KPx72ya6+PGjUqWU9df/29996rq6fBKpv/PaXK5wfA4+xHqzTsEXHdAIsfbEIvZtZE/risWSYcdrNMOOxmmXDYzTLhsJtlwqe4doDNmzcn62eccUaynhrCOvvss+vqabD2799f97q9vb2VnrtsSNIO5z27WSYcdrNMOOxmmXDYzTLhsJtlwmE3y4TDbpYJj7N3gGXLliXr5557brK+b9++mrWLLrqorp5aYcSIEZXWT/3e9nnes5tlwmE3y4TDbpYJh90sEw67WSYcdrNMOOxmmfA4ewdYvHhxsn7LLbck6wcOHKhZu+SSS+rqqVFS56xXvZR01fPhc+M9u1kmHHazTDjsZplw2M0y4bCbZcJhN8uEw26WicFM2TwFeBiYRN8Uzd0Rcb+k8cB/AlPpm7b52ojY3rxWj19Lly5N1vfu3Zusp6ZN3rJlS109NcquXbtq1iRVeuyq4/S5Gcye/VPgjog4D5gJfFfSecBdwAsRcRbwQvGzmXWo0rBHRE9ErChu7wLeAE4D5gALirstAK5qVpNmVt1RvWeXNBW4GHgFmBQRPUXpffpe5ptZhxr0Z+MljQF+C3w/Inb2f78VESEpaqw3D5hXtVEzq2ZQe3ZJw+gL+m8i4vFi8WZJk4v6ZGDAI0ER0R0R0yNieiMaNrP6lIZdfbvwB4E3IuJn/UpPAnOL23OBJxrfnpk1ymBexn8VuBF4TdLKYtndwL3AY5JuBdYD1zanxePf+vXrk/WdO3cm66lLMo8cOTK57rRp05L1t99+O1kvkzr9dujQamdYe+jt6JRu7Yh4Cag1IPq1xrZjZs3iT9CZZcJhN8uEw26WCYfdLBMOu1kmHHazTPhS0seAsqmNU+PNw4cPT67b7HH2np6emrWpU6cm1922bVuyPmSI91VHw1vLLBMOu1kmHHazTDjsZplw2M0y4bCbZcJhN8uEx9lboOySyREDXtHrM4sWLUrWr7/++pq1srHoWbNmJevPP/98sl5m9+7dda9btt127NhR92PnyHt2s0w47GaZcNjNMuGwm2XCYTfLhMNulgmH3SwTHmdvgarj7E88kZ5/46abbqpZS123HeCaa65J1ufPn5+sl0ldG77s9y6rl01lbYfznt0sEw67WSYcdrNMOOxmmXDYzTLhsJtlwmE3y0TpOLukKcDDwCQggO6IuF/SfODbwAfFXe+OiGea1eixrOyc8oMHDybrzz77bLK+ffv2mrWya86XPXdVq1evrlm74IILkuvu2bMnWT/11FPr6ilXg/lQzafAHRGxQtJJwKuSnitqP4+If2pee2bWKKVhj4geoKe4vUvSG8BpzW7MzBrrqN6zS5oKXAy8Uiz6nqRVkh6SNK7GOvMkLZe0vFKnZlbJoMMuaQzwW+D7EbET+AVwBtBF357/pwOtFxHdETE9IqY3oF8zq9Ogwi5pGH1B/01EPA4QEZsjojciDgIPADOa16aZVVUadvWdsvUg8EZE/Kzf8sn97nY1UPuwq5m13WCOxn8VuBF4TdLKYtndwHWSuugbjlsH3NaUDo8Dvb29TX38d999t2Zt5syZyXVHjx6drF922WXJ+tKlS5P11HTSI0eOTK47bNiwZH3ChAnJuh1uMEfjXwIGOiHbY+pmxxB/gs4sEw67WSYcdrNMOOxmmXDYzTLhsJtlwpeSboGySyJX1d3dXbP25ptvJtd99NFHk/WycfQyjzzySM3a2LFjk+vu2rUrWV+yZEldPeXKe3azTDjsZplw2M0y4bCbZcJhN8uEw26WCYfdLBNq9hjwYU8mfQCs77doAvBhyxo4Op3aW6f2Be6tXo3s7fSI+NJAhZaG/XNPLi3v1GvTdWpvndoXuLd6tao3v4w3y4TDbpaJdoe99oe6269Te+vUvsC91aslvbX1PbuZtU679+xm1iIOu1km2hJ2SVdI+j9JayTd1Y4eapG0TtJrkla2e366Yg69LZJW91s2XtJzkt4qvg84x16bepsvaVOx7VZKmt2m3qZIelHS65L+IOlviuVt3XaJvlqy3Vr+nl3SCcAfgb8ENgLLgOsi4vWWNlKDpHXA9Iho+wcwJP058DHwcEScXyz7R2BbRNxb/KMcFxE/6JDe5gMft3sa72K2osn9pxkHrgJupo3bLtHXtbRgu7Vjzz4DWBMRb0fEfuBRYE4b+uh4EbEY2HbE4jnAguL2Avr+WFquRm8dISJ6ImJFcXsXcGia8bZuu0RfLdGOsJ8GbOj380Y6a773AH4n6VVJ89rdzAAmRURPcft9YFI7mxlA6TTerXTENOMds+3qmf68Kh+g+7xZEXEJ8A3gu8XL1Y4Ufe/BOmnsdFDTeLfKANOMf6ad267e6c+rakfYNwFT+v385WJZR4iITcX3LcAiOm8q6s2HZtAtvm9pcz+f6aRpvAeaZpwO2HbtnP68HWFfBpwl6SuShgPfAp5sQx+fI2l0ceAESaOBr9N5U1E/Ccwtbs8FnmhjL4fplGm8a00zTpu3XdunP4+Iln8Bs+k7Ir8W+GE7eqjR1zTg98XXH9rdG7CQvpd1B+g7tnEr8EXgBeAt4HlgfAf19gjwGrCKvmBNblNvs+h7ib4KWFl8zW73tkv01ZLt5o/LmmXCB+jMMuGwm2XCYTfLhMNulgmH3SwTDrtZJhx2s0z8Pyz4cKIrcIYZAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Save the model*"
      ],
      "metadata": {
        "id": "15e7opwNd7hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "\n",
        "# Load a model\n",
        "model = MyModel2()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3wp3CyNd9vd",
        "outputId": "6d246814-ff6c-4d7b-c851-9718dd198ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    }
  ]
}