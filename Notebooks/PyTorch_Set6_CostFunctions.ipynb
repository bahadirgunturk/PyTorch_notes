{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqgHdJfxQsxb",
        "outputId": "2075f8fe-7981-4813-ece4-8fe09267c173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([2])\n",
            "Loss label encoded: tensor(4.5141)\n",
            "Loss one-hot encoded: tensor(4.5141)\n",
            "Loss one-hot encoded reversed: tensor(0.2243)\n",
            "LogSoftmax and NLLoss: tensor(4.5141)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# First, check out CrossEntropyLoss()\n",
        "f = torch.tensor([[-1., -3., 4.], [-3., 3., -1.]])\n",
        "print(f.shape)\n",
        "target = torch.tensor([0, 2])\n",
        "print(target.shape)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "print('Loss label encoded:',criterion(f, target)) \n",
        "# Note that, in the above, f has 3 logits, target has the label!\n",
        "\n",
        "# However, the following will return an error!\n",
        "#criterion(target, f)\n",
        "\n",
        "# So: criterion(logits, true_label) is ok...\n",
        "\n",
        "# how about one hot labeled target values\n",
        "target2 = torch.tensor([[1., 0., 0.], [0., 0., 1.]])\n",
        "print('Loss one-hot encoded:',criterion(f, target2))\n",
        "print('Loss one-hot encoded reversed:',criterion(target2, f))\n",
        "\n",
        "# So: be careful with the order. (Check out the cross-entropy formula.)\n",
        "\n",
        "# Instead of CrossEntropyLoss, you can have LogSoftmax and then NLLoss\n",
        "f = torch.tensor([[-1., -3., 4.], [-3., 3., -1.]])\n",
        "target = torch.tensor([0, 2])\n",
        "model = nn.LogSoftmax(dim = 1)  # Along the rows (logits)\n",
        "\n",
        "criterion = torch.nn.NLLLoss()\n",
        "print('LogSoftmax and NLLoss:',criterion(model(f), target))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom cost function\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def my_cross_entropy(y_pred,y_true):\n",
        "  # loss = -sum(y_true*log(softmax(y_pred)))\n",
        "\n",
        "  y_true = y_true.view(y_pred.size(0),-1)\n",
        "  \n",
        "  # To handle label-encoded y_true\n",
        "  if y_pred.size(1) != y_true.size(1):\n",
        "    y_true = F.one_hot(y_true, num_classes=y_pred.size(1)).view(y_pred.size())\n",
        "  \n",
        "  log_softmax = F.log_softmax(y_pred,dim=1)\n",
        "  loss = - y_true * log_softmax\n",
        "  loss = loss.sum(dim=1).mean()   # for multiple samples, take the mean()\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "y_pred = torch.tensor([[-1., -3., 4.], [-3., 3., -1.]])\n",
        "#y_true = torch.tensor([[1., 0., 0.], [0., 0., 1.]])\n",
        "y_true = torch.tensor([0,2])\n",
        "\n",
        "print(y_pred)\n",
        "print(y_true)\n",
        "\n",
        "loss = my_cross_entropy(y_pred,y_true)\n",
        "\n",
        "print(loss)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPiVGIHHNiTi",
        "outputId": "82943740-674d-4ccf-a4e2-516435556fb7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1., -3.,  4.],\n",
            "        [-3.,  3., -1.]])\n",
            "tensor([0, 2])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 1])\n",
            "tensor([[1, 0, 0],\n",
            "        [0, 0, 1]])\n",
            "tensor(4.5141)\n"
          ]
        }
      ]
    }
  ]
}