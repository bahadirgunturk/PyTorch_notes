{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NIzf09RxXY41"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sz_23M5skjfX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "image_size = 784\n",
        "num_epochs = 15\n",
        "batch_size = 128\n",
        "learning_rate = 1e-2\n",
        "\n",
        "# image transform\n",
        "transform1 = transforms.Compose([transforms.Resize(64),\n",
        "                                 transforms.Grayscale(3), #return 3 channels \n",
        "                                 transforms.ToTensor()])\n",
        "\n",
        "# download train dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./mnist_data/',\n",
        "                                           train=True,\n",
        "                                           transform=transform1,\n",
        "                                           download=True)\n",
        "\n",
        "# download test dataset\n",
        "test_dataset = torchvision.datasets.MNIST(root='./mnist_data/',\n",
        "                                           train=False,\n",
        "                                           transform=transform1,\n",
        "                                           download=True)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader =  torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out images in the dataset\n",
        "print(train_dataset)\n",
        "#print(train_dataset[0]) # is a tuple of (data,target)\n",
        "print(train_dataset[0][0].shape)  # image (a tensor)\n",
        "print(train_dataset[0][1])        # label (an integer)\n",
        "\n",
        "\n",
        "#print(train_dataset.data.shape)   # all images in the dataset\n",
        "\n",
        "# Look at a sample\n",
        "idx = 0\n",
        "image0 = train_dataset.data[idx]\n",
        "label0 = train_dataset.targets[idx]\n",
        "\n",
        "# The above image0 is of size [28,28], not yet transformed\n",
        "# Dataloader will do the transform and output it in batches\n",
        "image, label = next(iter(train_loader))\n",
        "# The image is of size [128,3,64,64]\n",
        "\n",
        "# To display a single image\n",
        "image1 = image[0].squeeze()     # get the 0th image in batch\n",
        "image1 = image1.permute(1,2,0)  # channel goes to the end\n",
        "image1 = image1.numpy()         # from tensor to numpy\n",
        "label1 = label[0].item()\n",
        "\n",
        "plt.imshow(image1)\n",
        "plt.title(label1)\n"
      ],
      "metadata": {
        "id": "-4-4TKzJVlzq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "86eafd7e-d027-40f1-c219-f1fcf11055c2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./mnist_data/\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=64, interpolation=bilinear, max_size=None, antialias=None)\n",
            "               Grayscale(num_output_channels=3)\n",
            "               ToTensor()\n",
            "           )\n",
            "torch.Size([3, 64, 64])\n",
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '9')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download a model "
      ],
      "metadata": {
        "id": "yHqhd9g2aq1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = torchvision.models.vgg19(pretrained=True).to(device)\n",
        "print(model1)\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "summary(model1, (1, 3, 32,32), col_names=[\"kernel_size\", \"output_size\", \"num_params\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "eyo0byJB3wPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4f7b35-0a21-4181-cd71-f3ef1e1b5596"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.8/dist-packages (1.7.1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===================================================================================================================\n",
              "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #\n",
              "===================================================================================================================\n",
              "VGG                                      --                        [1, 1000]                 --\n",
              "├─Sequential: 1-1                        --                        [1, 512, 1, 1]            --\n",
              "│    └─Conv2d: 2-1                       [3, 3]                    [1, 64, 32, 32]           1,792\n",
              "│    └─ReLU: 2-2                         --                        [1, 64, 32, 32]           --\n",
              "│    └─Conv2d: 2-3                       [3, 3]                    [1, 64, 32, 32]           36,928\n",
              "│    └─ReLU: 2-4                         --                        [1, 64, 32, 32]           --\n",
              "│    └─MaxPool2d: 2-5                    2                         [1, 64, 16, 16]           --\n",
              "│    └─Conv2d: 2-6                       [3, 3]                    [1, 128, 16, 16]          73,856\n",
              "│    └─ReLU: 2-7                         --                        [1, 128, 16, 16]          --\n",
              "│    └─Conv2d: 2-8                       [3, 3]                    [1, 128, 16, 16]          147,584\n",
              "│    └─ReLU: 2-9                         --                        [1, 128, 16, 16]          --\n",
              "│    └─MaxPool2d: 2-10                   2                         [1, 128, 8, 8]            --\n",
              "│    └─Conv2d: 2-11                      [3, 3]                    [1, 256, 8, 8]            295,168\n",
              "│    └─ReLU: 2-12                        --                        [1, 256, 8, 8]            --\n",
              "│    └─Conv2d: 2-13                      [3, 3]                    [1, 256, 8, 8]            590,080\n",
              "│    └─ReLU: 2-14                        --                        [1, 256, 8, 8]            --\n",
              "│    └─Conv2d: 2-15                      [3, 3]                    [1, 256, 8, 8]            590,080\n",
              "│    └─ReLU: 2-16                        --                        [1, 256, 8, 8]            --\n",
              "│    └─Conv2d: 2-17                      [3, 3]                    [1, 256, 8, 8]            590,080\n",
              "│    └─ReLU: 2-18                        --                        [1, 256, 8, 8]            --\n",
              "│    └─MaxPool2d: 2-19                   2                         [1, 256, 4, 4]            --\n",
              "│    └─Conv2d: 2-20                      [3, 3]                    [1, 512, 4, 4]            1,180,160\n",
              "│    └─ReLU: 2-21                        --                        [1, 512, 4, 4]            --\n",
              "│    └─Conv2d: 2-22                      [3, 3]                    [1, 512, 4, 4]            2,359,808\n",
              "│    └─ReLU: 2-23                        --                        [1, 512, 4, 4]            --\n",
              "│    └─Conv2d: 2-24                      [3, 3]                    [1, 512, 4, 4]            2,359,808\n",
              "│    └─ReLU: 2-25                        --                        [1, 512, 4, 4]            --\n",
              "│    └─Conv2d: 2-26                      [3, 3]                    [1, 512, 4, 4]            2,359,808\n",
              "│    └─ReLU: 2-27                        --                        [1, 512, 4, 4]            --\n",
              "│    └─MaxPool2d: 2-28                   2                         [1, 512, 2, 2]            --\n",
              "│    └─Conv2d: 2-29                      [3, 3]                    [1, 512, 2, 2]            2,359,808\n",
              "│    └─ReLU: 2-30                        --                        [1, 512, 2, 2]            --\n",
              "│    └─Conv2d: 2-31                      [3, 3]                    [1, 512, 2, 2]            2,359,808\n",
              "│    └─ReLU: 2-32                        --                        [1, 512, 2, 2]            --\n",
              "│    └─Conv2d: 2-33                      [3, 3]                    [1, 512, 2, 2]            2,359,808\n",
              "│    └─ReLU: 2-34                        --                        [1, 512, 2, 2]            --\n",
              "│    └─Conv2d: 2-35                      [3, 3]                    [1, 512, 2, 2]            2,359,808\n",
              "│    └─ReLU: 2-36                        --                        [1, 512, 2, 2]            --\n",
              "│    └─MaxPool2d: 2-37                   2                         [1, 512, 1, 1]            --\n",
              "├─AdaptiveAvgPool2d: 1-2                 --                        [1, 512, 7, 7]            --\n",
              "├─Sequential: 1-3                        --                        [1, 1000]                 --\n",
              "│    └─Linear: 2-38                      --                        [1, 4096]                 102,764,544\n",
              "│    └─ReLU: 2-39                        --                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-40                     --                        [1, 4096]                 --\n",
              "│    └─Linear: 2-41                      --                        [1, 4096]                 16,781,312\n",
              "│    └─ReLU: 2-42                        --                        [1, 4096]                 --\n",
              "│    └─Dropout: 2-43                     --                        [1, 4096]                 --\n",
              "│    └─Linear: 2-44                      --                        [1, 1000]                 4,097,000\n",
              "===================================================================================================================\n",
              "Total params: 143,667,240\n",
              "Trainable params: 143,667,240\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 522.08\n",
              "===================================================================================================================\n",
              "Input size (MB): 0.01\n",
              "Forward/backward pass size (MB): 2.50\n",
              "Params size (MB): 574.67\n",
              "Estimated Total Size (MB): 577.18\n",
              "==================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can access the modules/layers inside model\n",
        "#print(model1)\n",
        "#print(model1.features)\n",
        "#print(model1.avgpool)\n",
        "print(model1.classifier)\n",
        "print(model1.classifier[0])\n",
        "print(model1.classifier.parameters)\n"
      ],
      "metadata": {
        "id": "Ipgpbuc8eKk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e14f2b8-c458-4a88-b05a-a53b8585c903"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            ")\n",
            "Linear(in_features=25088, out_features=4096, bias=True)\n",
            "<bound method Module.parameters of Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get another copy of the model and play with it\n",
        "model2 = torchvision.models.vgg19(pretrained=True).to(device)\n",
        "\n",
        "# Freeze the parameters in the features part\n",
        "for param in model2.features.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "# Create an identity network; you can replace a part of the network\n",
        "#class identity_block(torch.nn.Module):\n",
        "#  def __init__(self):\n",
        "#    super().__init__()\n",
        "#  def forward(self,x):\n",
        "#    return x\n",
        "# For example, \n",
        "#model2.avgpool = identity_block()\n",
        "# OR\n",
        "#model2.avgpool = torch.nn.Identity()\n",
        "\n",
        "# Replace the last layer of the classifier to have 5 out_features\n",
        "#model2.classifier[6] = nn.Linear(in_features=4096,out_features=5)\n",
        "#print(model2)\n",
        "\n",
        "# Create a new classifier block\n",
        "class new_block(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(in_features=25088, out_features=100)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout1 = nn.Dropout()\n",
        "    self.linear2 = nn.Linear(in_features=100,out_features=5)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.dropout1(x)\n",
        "    x = self.linear2(x)\n",
        "    # x = self.dropout1(x) # Adding this would not change print(model) but\n",
        "    #   the forward process would change\n",
        "    #   Note that when you print(model), it does not show flattening...\n",
        "    return x\n",
        "\n",
        "# Replace the existing block\n",
        "model2.classifier = new_block()\n",
        "# OR \n",
        "'''\n",
        "model2.classifier = nn.Sequential(\n",
        "    nn.Linear(in_features=25088, out_features=100),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(in_features=100,out_features=5))\n",
        "'''\n",
        "\n",
        "print(model2)\n",
        "\n",
        "# Access a specific layer\n",
        "#print(model2.classifier.linear1)\n",
        "# OR\n",
        "#print(model2.classifier[0])\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "OXfBDjxC0xf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8d2500-e3bc-4e45-a56a-0e869776cef9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): new_block(\n",
            "    (linear1): Linear(in_features=25088, out_features=100, bias=True)\n",
            "    (relu): ReLU()\n",
            "    (dropout1): Dropout(p=0.5, inplace=False)\n",
            "    (linear2): Linear(in_features=100, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take part of a model\n",
        "#   Create a list and unpack it (with *) for nn.Sequential\n",
        "model_part = nn.Sequential(*[model2.features[i] for i in range(31)])\n",
        "print(model_part)\n",
        "\n",
        "# Check out the weights; they should be equal\n",
        "for param in model2.features[0].parameters():\n",
        "  print(param.data[0])\n",
        "  print(param.requires_grad)\n",
        "  \n",
        "\n",
        "for param in model_part[0].parameters():\n",
        "  print(param.data[0])\n",
        "  print(param.requires_grad)\n",
        "  "
      ],
      "metadata": {
        "id": "PElIZcqu37Ip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff87fb1d-5636-4667-bed3-9e41144ce8ab"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): ReLU(inplace=True)\n",
            "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): ReLU(inplace=True)\n",
            "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU(inplace=True)\n",
            "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (11): ReLU(inplace=True)\n",
            "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (13): ReLU(inplace=True)\n",
            "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (15): ReLU(inplace=True)\n",
            "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (17): ReLU(inplace=True)\n",
            "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (20): ReLU(inplace=True)\n",
            "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (22): ReLU(inplace=True)\n",
            "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (24): ReLU(inplace=True)\n",
            "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (26): ReLU(inplace=True)\n",
            "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (29): ReLU(inplace=True)\n",
            "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n",
            "tensor([[[-0.0535, -0.0493, -0.0679],\n",
            "         [ 0.0153,  0.0451,  0.0021],\n",
            "         [ 0.0362,  0.0200,  0.0199]],\n",
            "\n",
            "        [[ 0.0170,  0.0554, -0.0062],\n",
            "         [ 0.1416,  0.2271,  0.1376],\n",
            "         [ 0.1200,  0.2003,  0.0921]],\n",
            "\n",
            "        [[-0.0449,  0.0127, -0.0145],\n",
            "         [ 0.0597,  0.1395,  0.0541],\n",
            "         [-0.0010,  0.0583, -0.0297]]], device='cuda:0')\n",
            "False\n",
            "tensor(-0.9130, device='cuda:0')\n",
            "False\n",
            "tensor([[[-0.0535, -0.0493, -0.0679],\n",
            "         [ 0.0153,  0.0451,  0.0021],\n",
            "         [ 0.0362,  0.0200,  0.0199]],\n",
            "\n",
            "        [[ 0.0170,  0.0554, -0.0062],\n",
            "         [ 0.1416,  0.2271,  0.1376],\n",
            "         [ 0.1200,  0.2003,  0.0921]],\n",
            "\n",
            "        [[-0.0449,  0.0127, -0.0145],\n",
            "         [ 0.0597,  0.1395,  0.0541],\n",
            "         [-0.0010,  0.0583, -0.0297]]], device='cuda:0')\n",
            "False\n",
            "tensor(-0.9130, device='cuda:0')\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, pass a random input, check out the dimension of the model_part\n",
        "#image, label = next(iter(train_loader))\n",
        "image = torch.randn((1,3,64,64)).to(device)\n",
        "y = model_part(image)\n",
        "print(y.shape)\n",
        "#>> torch.Size([1, 512, 4, 4])\n",
        "\n",
        "# Using shape info, you can create a new block and append to model_part\n",
        "model_part2 = nn.Sequential(\n",
        "    nn.Flatten(),   \n",
        "    # The above is part of nn.module. Compare with nn.flatten()\n",
        "    # ... If a class is written, in .forward, you can write x.view(-1,512*4*4)\n",
        "    # For vgg19, print(model) doesn't display .forward but the defined layers\n",
        "    nn.Linear(in_features=512*4*4, out_features=100),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.Linear(in_features=100,out_features=10))\n",
        "\n",
        "#print(model_part2)\n",
        "\n",
        "# Append these blocks\n",
        "model3 = nn.Sequential(model_part,model_part2).to(device)\n",
        "print(model3)\n",
        "#print(model3[0][0])\n",
        "\n",
        "y2 = model3(image)\n",
        "print(y2.shape)\n"
      ],
      "metadata": {
        "id": "adbcPPYX607A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3549ba-2f1a-4c88-d5cd-f580a3e021f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 512, 4, 4])\n",
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (1): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=8192, out_features=100, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's train\n",
        "loss_function = torch.nn.CrossEntropyLoss()     \n",
        "optimizer = torch.optim.SGD(model3.parameters(),lr=0.001)\n",
        "\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "# Define a function to train the model for one epoch\n",
        "def train_model(train_loader):\n",
        "  \n",
        "  # Put model in train mode\n",
        "  model3.train()\n",
        "\n",
        "  # For loss calculation\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  dataset_size = len(train_loader.dataset)\n",
        "\n",
        "  # Go over each batch\n",
        "  for X, y in train_loader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    y_pred = model3(X)\n",
        "\n",
        "    loss = loss_function(y_pred,y)  \n",
        "    # In the above\n",
        "    #   input:y_pred is logits, target y is integer index.\n",
        "    #   target could also be a vector of probabilities\n",
        "    #     in that case, y.softmax(1) could be used to convert to probabilities  \n",
        "    \n",
        "    # Zero the gradients, backpropagate the gradients, update the parameters\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate loss\n",
        "    total_loss += loss_function(y_pred, y).item()\n",
        "    total_correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  print(f\"Training Loss:{total_loss/dataset_size:0.4f}, \\\n",
        "          Training Accuracy:{total_correct/dataset_size:0.4f}\")\n",
        "\n",
        "\n",
        "# Define a function to test the model\n",
        "def test_model(test_loader):\n",
        "  # Put the model into evaluation mode\n",
        "  model3.eval()\n",
        "\n",
        "  # For loss calculation\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  dataset_size = len(test_loader.dataset)\n",
        "\n",
        "  # Do not calculate gradients\n",
        "  with torch.no_grad():\n",
        "    for X,y in test_loader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      y_pred = model3(X)\n",
        "\n",
        "      # Calculate loss\n",
        "      total_loss += loss_function(y_pred, y).item()\n",
        "      total_correct += (y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  \n",
        "  print(f\"Test Loss: {total_loss/dataset_size:0.4f}, \\\n",
        "          Test Accuracy: {total_correct/dataset_size:0.4f}\")\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print('Epoch:',epoch)\n",
        "  # Train loss\n",
        "  train_model(train_loader)\n",
        "\n",
        "  # Test loss\n",
        "  test_model(test_loader)"
      ],
      "metadata": {
        "id": "ZNLyC75tB5Qv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}