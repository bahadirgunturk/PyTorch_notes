{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usG3F0MmGhCM"
      },
      "source": [
        "**RNN**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI2ZXnToPYQD"
      },
      "source": [
        "*Let's write a simple Recurrent Neural Network* \n",
        "\n",
        "h(t) = ReLU( W_x2h * x(t) + W_h2h * h(t-1) + bh )\n",
        "\n",
        "y(t) = W_h2y * h(t) + by\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_61MFQkb3Em"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class myRNN(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim,output_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.W_x2h = nn.Linear(input_dim,hidden_dim,bias=True)\n",
        "    self.W_h2h = nn.Linear(hidden_dim,hidden_dim,bias=False)\n",
        "    self.W_h2y = nn.Linear(hidden_dim,output_dim,bias=True)\n",
        "  \n",
        "  # input is of size (batch_size, sequence_length, input_dim)\n",
        "  def forward(self,input):\n",
        "    # Calculate hidden state for each sample in the batch\n",
        "    h = torch.zeros((input.size(0),self.hidden_dim))\n",
        "    \n",
        "    # Go over the sequence \n",
        "    for t in range(input.size(1)):\n",
        "      h = F.relu( self.W_x2h(input[:,t]) + self.W_h2h(h) )\n",
        "      # Not calculating intermediate outputs\n",
        "\n",
        "    pred = self.W_h2y(h)\n",
        "    # return the final output and h\n",
        "    return pred, h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13K3xkEHkB_W",
        "outputId": "a7b9a297-2f85-4bd6-baf6-044b6e126150"
      },
      "outputs": [],
      "source": [
        "model = myRNN(4,10,2) #(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "input = torch.randn(3,100,4) #(batch_size,sequence_length,input_dim)\n",
        "\n",
        "print(\"Input shape at an instant: \",input[:,0].shape) #(batch_size,input_dim)\n",
        "\n",
        "y,h = model(input)\n",
        "print(\"Output shape: \",y.shape)\n",
        "print(\"Hidden state shape: \",h.shape)\n",
        "\n",
        "# You can print the weights\n",
        "print(model.W_x2h.weight)\n",
        "print(model.W_x2h.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RM_pVmdbVbj"
      },
      "source": [
        "*Let's now use nn.RNN*\n",
        "\n",
        "*The output of nn.RNN is hidden state values at all time steps. It is of size (batch_size, sequence_length, hidden_size x num_directions) if batch_first=True; otherwise, (sequence_length, batch_size, num_directions * hidden_size)*\n",
        "\n",
        "*num_directions is 2 for bidirectional RNN, where the data is input in the reverse order to a secondary network.* \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9-E20xKGll0",
        "outputId": "7cd24039-4c14-4eaf-a58d-ed78c815c491"
      },
      "outputs": [],
      "source": [
        "rnn_model = nn.RNN(input_size=4, hidden_size=10, num_layers=1, batch_first=True)\n",
        "\n",
        "print(rnn_model)\n",
        "\n",
        "print('# Print the initial input-to-hidden weights and biases')\n",
        "print(rnn_model.weight_ih_l0)\n",
        "print(rnn_model.bias_ih_l0)\n",
        "\n",
        "# If there is a second layer, rnn_layer.weight_ih_l1, ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swJuX_dhv6Hw",
        "outputId": "d05f3e7e-83f6-4a69-c829-51faa10d5759"
      },
      "outputs": [],
      "source": [
        "# Note that there is no separate output; the hidden state is used as the output\n",
        "y,h = rnn_model(input)\n",
        "print(\"Output shape: \",y.shape) # Note that we have the hidden states all time\n",
        "print(\"Hidden state shape: \",h.shape) # Note that the first dim is for the layers\n",
        "\n",
        "print(y[:,-1,:])\n",
        "print(h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMbsTu9FyDyK"
      },
      "source": [
        "*Let's now use nn.LSTM*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENMUF2nyyISR",
        "outputId": "7ac9ea6a-dbbe-427b-ac8d-5843168fabb9"
      },
      "outputs": [],
      "source": [
        "lstm_model = nn.LSTM(input_size=4, hidden_size=10, num_layers=1,batch_first = True)\n",
        "\n",
        "y,(h,c) = lstm_model(input)\n",
        "\n",
        "print(y.shape)\n",
        "print(h.shape)\n",
        "print(c.shape)\n",
        "\n",
        "print(y[0,-1,:])  # y is the hidden state for all time steps\n",
        "print(h[0,0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE7iCpsizkNN",
        "outputId": "3a8faba6-7ef2-46d1-87d6-00b031dfce71"
      },
      "outputs": [],
      "source": [
        "# You can increase the number of layers\n",
        "lstm_model = nn.LSTM(input_size=4, hidden_size=10, num_layers=2,batch_first = True)\n",
        "\n",
        "y,(h,c) = lstm_model(input)\n",
        "\n",
        "print(y.shape)\n",
        "print(h.shape)  # Note that we have hidden states for each layer\n",
        "print(c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RblmPylYzyJ5",
        "outputId": "f68a23a5-604e-4aea-c899-eb0348ab7422"
      },
      "outputs": [],
      "source": [
        "# You can have bidirectional lstm\n",
        "lstm_model = nn.LSTM(input_size=4, hidden_size=10, num_layers=2,bidirectional=True, batch_first = True)\n",
        "\n",
        "y,(h,c) = lstm_model(input)\n",
        "\n",
        "print(y.shape)\n",
        "print(h.shape)  # Note that we have the hidden states for each direction\n",
        "print(c.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfcD1EG80iUZ"
      },
      "source": [
        "*Finally, let's try nn.GRU*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V81XGoCD0g0L",
        "outputId": "a25acfd2-7ce2-43d4-b068-7c44d6c78c86"
      },
      "outputs": [],
      "source": [
        "gru_model = nn.GRU(input_size=4, hidden_size=10, num_layers=1,batch_first=True)\n",
        "\n",
        "y,h = gru_model(input)\n",
        "\n",
        "print(y.shape)\n",
        "print(h.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiZD0DSAImpq"
      },
      "source": [
        "*Let's now do a time-series prediction*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GDLQU7NItTE",
        "outputId": "96159b3e-b9c8-4196-98c2-2873826e9000"
      },
      "outputs": [],
      "source": [
        "# Let's download a dataset\n",
        "\n",
        "# The dataset consists of (month,num_of_passengers) over 144 months\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "iPQrK5xH2AWu",
        "outputId": "7408fd31-b47b-4636-86dd-387f3d765c13"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv('airline-passengers.csv')\n",
        "print(dataset.head())\n",
        "\n",
        "# Use 75% of data for training, the rest for testing\n",
        "id_train_cut = int( 0.75 * len(dataset) )\n",
        "\n",
        "train_set = dataset.iloc[0:id_train_cut,1:2].values\n",
        "test_set = dataset.iloc[id_train_cut:-1,1:2].values\n",
        "\n",
        "plt.plot(train_set)\n",
        "plt.plot(test_set)\n",
        "\n",
        "print(train_set[0:4].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "mS-fwA575ya9",
        "outputId": "b59c3050-05c7-4757-ff57-1ee7da50a037"
      },
      "outputs": [],
      "source": [
        "# Note that the range of data is large. We need to scale it.\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "train_set = scaler.fit_transform(train_set)\n",
        "\n",
        "\n",
        "plt.plot(train_set)\n",
        "\n",
        "# Inverse transform \n",
        "checkout_train_set = scaler.inverse_transform(train_set)\n",
        "plt.figure()\n",
        "plt.plot(checkout_train_set)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QWrAbgt3-SH",
        "outputId": "374ea99b-f204-471b-a253-fe0d302c13f6"
      },
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "\n",
        "# Use sliding window to use part of data as input, and next one to predict\n",
        "\n",
        "def prepare_data (data,sequence_length):\n",
        "  X = [] # empty list to be filled in\n",
        "  y = []\n",
        "\n",
        "  for i in range( len(data)-sequence_length - 1 ):\n",
        "    Xi = data[i:i+sequence_length]\n",
        "    yi = data[i+sequence_length]\n",
        "    \n",
        "    X.append(Xi)\n",
        "    y.append(yi)\n",
        "  \n",
        "  # Convert list to numpy\n",
        "  X = np.array(X).astype(np.float32)\n",
        "  y = np.array(y).astype(np.float32)\n",
        "\n",
        "  return torch.from_numpy(X), torch.from_numpy(y)\n",
        "\n",
        "sequence_length = 5\n",
        "\n",
        "train_X, train_y = prepare_data(train_set,sequence_length)\n",
        "test_X, test_y = prepare_data(test_set,sequence_length)\n",
        "\n",
        "print(train_X.shape, train_y.shape)\n",
        "print(test_X.shape, test_y.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RU10J26mvJP4"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "\n",
        "class SeqModel(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim,output_dim,num_layers=1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=input_dim, \n",
        "                        hidden_size=hidden_dim,\n",
        "                        num_layers=num_layers, \n",
        "                        batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim,output_dim)\n",
        "\n",
        "  def forward(self,input):\n",
        "    y, (h,c) = self.lstm(input)\n",
        "\n",
        "    h = h.view(-1,self.hidden_dim)\n",
        "\n",
        "    #print(h.shape)\n",
        "\n",
        "    pred = self.fc(h)\n",
        "\n",
        "    return pred\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkIjDqy51dpt",
        "outputId": "6ba203bf-a417-4f55-a06e-92abdb0ad7ec"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "\n",
        "# Note that we have input_dim 1, and sequence_length 5\n",
        "model = SeqModel(input_dim=1,hidden_dim=8,output_dim=1)\n",
        "\n",
        "pred = model(train_X)\n",
        "\n",
        "print(pred.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oULD0rjR4Fyp",
        "outputId": "b48ba569-4998-4ea4-a7bc-a1e131b2049f"
      },
      "outputs": [],
      "source": [
        "# Train the model \n",
        "\n",
        "num_epochs = 2000\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  pred = model(train_X)\n",
        "\n",
        "  loss = criterion(pred, train_y)\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(\"Epoch: \",epoch, \", Loss: \",loss.item())\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "lbDTBDOX8Lzl",
        "outputId": "d7cd18f5-9482-4009-df16-b21bf0943652"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "\n",
        "model.eval()\n",
        "\n",
        "test_X, test_y = prepare_data(test_set,sequence_length) \n",
        "\n",
        "test_set_sc = scaler.transform(test_set)\n",
        "test_X_sc, test_y_sc = prepare_data(test_set_sc,sequence_length) \n",
        "\n",
        "pred_sc = model(test_X_sc).detach()\n",
        "pred = scaler.inverse_transform(pred_sc)\n",
        "\n",
        "plt.plot(test_y,'r')\n",
        "plt.plot(pred,'b')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
